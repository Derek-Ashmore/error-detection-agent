name: PR Verification

on:
  pull_request:
    branches:
      - main
      - develop
    types:
      - opened
      - synchronize
      - reopened

# Ensure only one workflow runs at a time per PR
concurrency:
  group: pr-verify-${{ github.event.pull_request.number }}
  cancel-in-progress: true

jobs:
  verify:
    name: Verify PR
    runs-on: ubuntu-latest

    permissions:
      contents: read
      pull-requests: write
      issues: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci
        env:
          NODE_ENV: development

      - name: Run linting
        id: lint
        run: |
          npm run lint 2>&1 | tee lint-errors.txt || true
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "lint_failed=true" >> $GITHUB_OUTPUT
          else
            echo "lint_failed=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run type checking
        id: typecheck
        run: |
          npm run typecheck 2>&1 | tee typecheck-errors.txt || true
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "typecheck_failed=true" >> $GITHUB_OUTPUT
          else
            echo "typecheck_failed=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run tests with coverage
        id: test
        run: |
          npm test -- --coverage --ci --maxWorkers=2 2>&1 | tee test-errors.txt || true
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "test_failed=true" >> $GITHUB_OUTPUT
          else
            echo "test_failed=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true
        env:
          NODE_ENV: test

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage/coverage-final.json
          flags: unittests
          name: pr-${{ github.event.pull_request.number }}
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Comment PR with coverage
        uses: actions/github-script@v7
        if: always()
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            let coverageComment = '## Coverage Report\n\n';

            try {
              const summary = JSON.parse(fs.readFileSync('./coverage/coverage-summary.json', 'utf8'));
              const total = summary.total;

              coverageComment += '| Metric | Coverage |\n';
              coverageComment += '|--------|----------|\n';
              coverageComment += `| Lines | ${total.lines.pct}% |\n`;
              coverageComment += `| Statements | ${total.statements.pct}% |\n`;
              coverageComment += `| Functions | ${total.functions.pct}% |\n`;
              coverageComment += `| Branches | ${total.branches.pct}% |\n`;
            } catch (error) {
              coverageComment += 'Coverage report not available.\n';
            }

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Coverage Report')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: coverageComment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: coverageComment
              });
            }

      - name: Archive test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: |
            coverage/
            test-results/
          retention-days: 30

      - name: Check build
        id: build
        run: |
          npm run build 2>&1 | tee build-errors.txt || true
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "build_failed=true" >> $GITHUB_OUTPUT
          else
            echo "build_failed=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true
        env:
          NODE_ENV: production

      - name: Capture error details
        if: always() && (steps.lint.outputs.lint_failed == 'true' || steps.typecheck.outputs.typecheck_failed == 'true' || steps.test.outputs.test_failed == 'true' || steps.build.outputs.build_failed == 'true')
        run: |
          mkdir -p error-reports
          {
            echo "# Error Report for PR #${{ github.event.pull_request.number }}"
            echo ""
            echo "## Summary"
            echo "- Linting: ${{ steps.lint.outcome }}"
            echo "- Type Checking: ${{ steps.typecheck.outcome }}"
            echo "- Tests: ${{ steps.test.outcome }}"
            echo "- Build: ${{ steps.build.outcome }}"
            echo ""
          } > error-reports/summary.md
          
          if [ -f lint-errors.txt ] && [ -s lint-errors.txt ]; then
            {
              echo "## Linting Errors"
              echo "\`\`\`"
              cat lint-errors.txt
              echo "\`\`\`"
              echo ""
            } >> error-reports/summary.md
          fi
          
          if [ -f typecheck-errors.txt ] && [ -s typecheck-errors.txt ]; then
            {
              echo "## Type Checking Errors"
              echo "\`\`\`"
              cat typecheck-errors.txt
              echo "\`\`\`"
              echo ""
            } >> error-reports/summary.md
          fi
          
          if [ -f test-errors.txt ] && [ -s test-errors.txt ]; then
            {
              echo "## Test Errors"
              echo "\`\`\`"
              cat test-errors.txt
              echo "\`\`\`"
              echo ""
            } >> error-reports/summary.md
          fi
          
          if [ -f build-errors.txt ] && [ -s build-errors.txt ]; then
            {
              echo "## Build Errors"
              echo "\`\`\`"
              cat build-errors.txt
              echo "\`\`\`"
            } >> error-reports/summary.md
          fi

      - name: Post errors for Claude auto-fix
        if: always() && (steps.lint.outputs.lint_failed == 'true' || steps.typecheck.outputs.typecheck_failed == 'true' || steps.test.outputs.test_failed == 'true' || steps.build.outputs.build_failed == 'true')
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Check step outputs for failures
            const lintFailed = '${{ steps.lint.outputs.lint_failed }}' === 'true';
            const typecheckFailed = '${{ steps.typecheck.outputs.typecheck_failed }}' === 'true';
            const testFailed = '${{ steps.test.outputs.test_failed }}' === 'true';
            const buildFailed = '${{ steps.build.outputs.build_failed }}' === 'true';
            
            if (!lintFailed && !typecheckFailed && !testFailed && !buildFailed) {
              console.log('No errors detected, skipping error posting');
              return;
            }
            
            let errorBody = '## ‚ùå PR Verification Failed - Auto-Fix Request\n\n';
            errorBody += 'This PR has encountered errors during verification. ';
            errorBody += 'Please review and fix the following issues:\n\n';
            
            try {
              const summary = fs.readFileSync('./error-reports/summary.md', 'utf8');
              errorBody += summary;
            } catch (error) {
              errorBody += 'Error details could not be captured.\n';
            }
            
            errorBody += '\n---\n\n';
            errorBody += '**ü§ñ Claude Auto-Fix Instructions:**\n\n';
            errorBody += 'Please analyze the errors above and automatically fix them by:\n';
            errorBody += '1. Reviewing the error messages\n';
            errorBody += '2. Identifying the root causes\n';
            errorBody += '3. Applying fixes directly to the PR\n';
            errorBody += '4. Verifying the fixes resolve all issues\n\n';
            errorBody += '**Files that may need attention:**\n';
            
            // Get changed files
            const { data: files } = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
            });
            
            // Sanitize filenames to prevent issues with maliciously crafted names
            function sanitizeFilename(filename) {
              // Remove control characters, limit length, and escape backticks
              let sanitized = filename.replace(/[\u0000-\u001F\u007F]/g, ''); // remove control chars
              sanitized = sanitized.replace(/`/g, '\\`'); // escape backticks
              if (sanitized.length > 200) {
                sanitized = sanitized.slice(0, 200) + '...';
              }
              return sanitized;
            }

            const changedFiles = files
              .filter(f => f.status !== 'removed')
              .map(f => `- \`${sanitizeFilename(f.filename)}\``)
              .slice(0, 20);
            
            if (changedFiles.length > 0) {
              errorBody += changedFiles.join('\n');
            } else {
              errorBody += '- Unable to determine changed files';
            }
            
            // Find existing error comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const errorComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('PR Verification Failed')
            );
            
            if (errorComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: errorComment.id,
                body: errorBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: errorBody
              });
            }
            
            // Also create a label to help identify PRs needing fixes
            try {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                labels: ['needs-fix', 'claude-auto-fix']
              });
            } catch (error) {
              // Labels might not exist, that's okay
              console.log('Could not add labels:', error.message);
            }

      - name: Archive error reports
        if: always() && (steps.lint.outputs.lint_failed == 'true' || steps.typecheck.outputs.typecheck_failed == 'true' || steps.test.outputs.test_failed == 'true' || steps.build.outputs.build_failed == 'true')
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: error-reports
          path: |
            error-reports/
            lint-errors.txt
            typecheck-errors.txt
            test-errors.txt
            build-errors.txt
          retention-days: 7
          if-no-files-found: ignore

      - name: Archive build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: dist/
          retention-days: 7

      - name: Fail workflow if errors occurred
        if: always()
        run: |
          # Check step outputs for failures
          if [ "${{ steps.lint.outputs.lint_failed }}" = "true" ]; then
            echo "‚ùå Linting errors detected"
            HAS_ERRORS=true
          fi
          if [ "${{ steps.typecheck.outputs.typecheck_failed }}" = "true" ]; then
            echo "‚ùå Type checking errors detected"
            HAS_ERRORS=true
          fi
          if [ "${{ steps.test.outputs.test_failed }}" = "true" ]; then
            echo "‚ùå Test errors detected"
            HAS_ERRORS=true
          fi
          if [ "${{ steps.build.outputs.build_failed }}" = "true" ]; then
            echo "‚ùå Build errors detected"
            HAS_ERRORS=true
          fi
          
          if [ "$HAS_ERRORS" = "true" ]; then
            echo "‚ùå PR verification failed. Errors have been posted for Claude auto-fix."
            echo "::error::PR verification failed. Check the PR comments for error details and Claude's auto-fix."
            exit 1
          else
            echo "‚úÖ All checks passed"
          fi
